---
title: "非线性回归"
subtitle: ""
author: "冯凌秉"
institute: "<span style = 'font-size: 70%;'>
  江西财经大学 <br> 
  产业经济研究院</span>"
date: '2020<br><br>
  `r icon::fa("paper-plane")` <feng.lingbing@jxufe.edu.cn>'
output:
  xaringan::moon_reader:
    css: [default, zh-CN.css]
    lib_dir: libs
    includes:
      after_body: insert-logo.html
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---
```{r, setup, include=FALSE,echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = ">", 
                      fig.retina = 3, warning = FALSE, message = FALSE)
library(RefManageR)
library(AER)
library(stargazer)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
BibOptions(check.entries = FALSE, bib.style = "authoryear", style = "markdown", dashed = TRUE)
bib <- ReadBib("bib1.bib")
```

# 多项式回归：二次项
在CASchools数据的例子中，我们研究学区居民的收入和学生测试成绩的关系。
由相关系数可知，该对变量的线性相关关系是显著的。

```{r}
library(AER)                                                     
data(CASchools)
CASchools$size <- CASchools$students/CASchools$teachers
CASchools$score <- (CASchools$read + CASchools$math) / 2   
cor(CASchools$income, CASchools$score)
```

下图中我们给出简单回归直线和二次回归的拟合直线：

$$TestScore_i = \beta_0 + \beta_1 \times income_i + \beta_2 \times income_i^2 + u_i,$$
---
# 二次项回归
.pull-left[
```{r plot_1, fig.show='hide'}
linear_model<- lm(score ~ income, data = CASchools)
plot(CASchools$income, CASchools$score,
     col = "steelblue",
     pch = 20,
     xlab = "District Income (thousands of dollars)", 
     ylab = "Test Score",
     cex.main = 0.9,
     main = "Test Score vs. District Income and a Linear OLS Regression Function")
abline(linear_model, 
       col = "red", 
       lwd = 2)
quadratic_model <- lm(score ~ income + I(income^2), data = CASchools)
plot(CASchools$income, CASchools$score,
     col  = "steelblue",
     pch = 20,
     xlab = "District Income (thousands of dollars)",
     ylab = "Test Score",
     main = "Estimated Linear and Quadratic Regression Functions")
abline(linear_model, col = "black", lwd = 2)
order_id <- order(CASchools$income)
lines(x = CASchools$income[order_id], 
      y = fitted(quadratic_model)[order_id],
      col = "red", 
      lwd = 2) 
```
]

.pull-right[
```{r ref.label = 'plot_1', echo=F, fig.height=7}
```
]

---
# 二次项系数估计
```{r}
coeftest(quadratic_model, vcov. = vcovHC, type = "HC1")
```

$$\widehat{TestScore}_i = \underset{(2.90)}{607.3} + \underset{(0.27)}{3.85} \times income_i - \underset{(0.0048)}{0.0423} \times income_i^2.$$
二次项系数估计为-0.0423，并且在1%的显著性水平下是显著的。

因此用一个**倒U形**来拟合二者的关系更加合适。

---
# 多项式回归

在二次项回归的基础上，我们可以增加X变量的幂级，建立r阶多项式回归
$$Y_i = \beta_0 + \beta_1 X_i + \beta_2 X_i^2 + \cdots + \beta_r X_i^r + u_i.$$
可以用如下命令建立三次式回归
```{r}
cubic_model <- lm(score ~ poly(income, degree = 3, raw = TRUE), data = CASchools)
```

为了检验二次和三次式是否显著，我们可以使用如下联合检验
$$H_0: \beta_2=0, \ \beta_3=0,\dots,\beta_r=0 \ \ \ \text{vs.} \ \ \ H_1: \text{at least one} \ \beta_j\neq0, \ j=2,\dots,r$$
R命令如下

```{r eval=F}
R <- rbind(c(0, 0, 1, 0), c(0, 0, 0, 1))
linearHypothesis(cubic_model, white.adj = "hc1",
                 hypothesis.matrix = R)
```


---
# 检验矩阵
.pull-left[

此处的检验矩阵设定是因为
$$\begin{align*}
  \mathbf{R}{\beta} =& \mathbf{s} \\
  \begin{pmatrix}
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{pmatrix}
  \begin{pmatrix}
    \beta_0 \\
    \beta_1 \\
    \beta_2 \\
    \beta_3 \\
  \end{pmatrix} =&
  \begin{pmatrix}
   0 \\
   0
  \end{pmatrix} \\
  \begin{pmatrix}
    \beta_2 \\
    \beta_3
  \end{pmatrix}= &
  \begin{pmatrix}
    0 \\
    0
  \end{pmatrix}.
\end{align*}$$
]
.pull-right[
```{r echo=F, highlight.output=14}
R <- rbind(c(0, 0, 1, 0),c(0, 0, 0, 1))
linearHypothesis(cubic_model,white.adj = "hc1",
                 hypothesis.matrix = R)
```
]

---
# 三次多项式回归模型估计
```{r}
tab_model(cubic_model)
```

### 三次项系数估计不显著
我们改用稳健估计

---
```{r echo=F}
tab_model(quadratic_model,cubic_model, 
          emph.p = T, title = "Regression Outputs",
          show.ci = F, collapse.se = T, digits = 4,
          p.style = "a", vcov.fun = "vcovHC", vcov.type = "HC1")
```
利用稳健估计后，三次项系数估计变为显著。但是三次项系数估计很小，是否留在模型中？

---
# 多项式回归的系数解释
多项式回归的系数不能按照多元回归的解释套路得到解释。为什么？

因为不能说在给定X和X立方不变的情况下，单位变化的X平方将引起Y多大程度的变化。X平方变化并将导致X和X立方的变化。

可以通过对多项式某一项的变化所导致的Y预测值的变化来测度多项式系数的边际效应：
$$\Delta \widehat{Y} = \hat{f}(X_1 + \Delta X_1, X_2, \cdots, X_k) - \hat{f}(X_1, X_2, \cdots, X_k).$$
而且，应该注意到，以下两种单位幅度的变化的边际效应是不同的

1. income从10增加到11

2. income从40增加到41

---
# 多项式回归系数解释
```{r}
quadriatic_model <- lm(score ~ income + I(income^2), data = CASchools)
new_data <- data.frame(income = c(10, 11))
Y_hat <- predict(quadriatic_model, newdata = new_data)
diff(Y_hat)
new_data <- data.frame(income = c(40, 41))
Y_hat <- predict(quadriatic_model, newdata = new_data)
diff(Y_hat)
```

[思考]：这种边际效应差异的原因是什么？线性回归中有没有这种差异存在？

---
# 对数变换
变换之后，对回归系数的估计都变得不一样了，我们在解释的时候要十分慎重。
.left-column[
对数变换可以

1. 缩小量纲

2. 改善偏度

我们可以对
1. X对数变换

2. Y对数变换

3. X和Y同时变换
]

.right-column[
```{r}
LinearLog_model <- lm(score ~ log(income), data = CASchools)
coeftest(LinearLog_model, 
         vcov = vcovHC, type = "HC1")
```
$$\widehat{TestScore} = 557.8 + 36.42 \times \ln(income).$$
]

---
# Linear-Log 回归线
.pull-left[
对 $\hat{\beta_1}$ 可以解释为：**income 每增加1%**，score增加 $0.01 \times 36.42 = 0.36$ 分。
[*请证明之*]
```{r plot_linear_log, fig.show='hide'}
plot(score ~ income, 
     col = "steelblue",
     pch = 20,
     data = CASchools,
     main = "Linear-Log Regression Line")
order_id  <- order(CASchools$income)
lines(CASchools$income[order_id],
      fitted(LinearLog_model)[order_id], 
      col = "red", 
      lwd = 2)
new_data <- data.frame(income = c(10, 11, 40, 41))
Y_hat <- predict(LinearLog_model, newdata = new_data)
Y_hat_matrix <- matrix(Y_hat, nrow = 2, byrow = TRUE)
Y_hat_matrix[, 2] - Y_hat_matrix[, 1]
```
]

.pull-right[
```{r ref.label = 'plot_linear_log', echo=F, fig.height=7}
```
]

---
# Y对数变换
模型为
$$\ln(Y_i) = \beta_0 + \beta_1 \times X_i + u_i , \ \ i=1,...,n.$$
```{r}
LogLinear_model <- lm(log(score) ~ income, data = CASchools)
coeftest(LogLinear_model, 
         vcov = vcovHC, type = "HC1")
```
估计模型为：
$$\widehat{\ln(TestScore)} = 6.439 + 0.00284 \times income.$$

解释为：income每增加一个单位 (1000美金)，score增加 $100 \times 0.00284 \% = 0.284\%$。

---
# X和Y同时对数变换
模型为:
$$\ln(Y_i) = \beta_0 + \beta_1 \times \ln(X_i) + u_i, \ \ i=1,...,n.$$
```{r}
LogLog_model <- lm(log(score) ~ log(income), data = CASchools)
coeftest(LogLog_model, 
         vcov = vcovHC, type = "HC1")
```
估计模型为
$$\widehat{\ln(TestScore)} = 6.336 + 0.0554 \times \ln(income).$$
解释为：income每增加1%，score增加 $\hat\beta_1 \%$。

---
# 对数变换效果
.pull-left[
注意图中的Y变量已经事先做了对数变换

```{r plot_log_log, fig.show='hide'}
plot(log(score) ~ income, 
     col = "steelblue", 
     pch = 20, 
     data = CASchools,
     main = "Log-Linear Regression Function")
order_id  <- order(CASchools$income)
lines(CASchools$income[order_id], 
      fitted(LogLinear_model)[order_id], 
      col = "red", 
      lwd = 2)
lines(sort(CASchools$income), 
      fitted(LogLog_model)[order(CASchools$income)], 
      col = "green", 
      lwd = 2)
legend("bottomright",
       legend = c("log-linear model", "log-log model"),
       lwd = 2,
       col = c("red", "green"))    
```
]

.pull-right[
```{r ref.label = 'plot_log_log', echo=F, fig.height=7}
```
]

---
# 多项式模型还是对数模型
.pull-left[
```{r}
polyLog_model <- lm(score ~ log(income) + I(log(income)^2) + I(log(income)^3), data = CASchools)
adj_R2 <-rbind("quadratic" = summary(quadratic_model)$adj.r.squared,
               "cubic" = summary(cubic_model)$adj.r.squared,
               "LinearLog" = summary(LinearLog_model)$adj.r.squared,
               "LogLinear" = summary(LogLinear_model)$adj.r.squared,
               "LogLog" = summary(LogLog_model)$adj.r.squared,
               "polyLog" = summary(polyLog_model)$adj.r.squared)

# assign column names
colnames(adj_R2) <- "adj_R2"
adj_R2
```
]
.pull-right[
```{r echo=F}
plot(score ~ income, 
     data = CASchools,
     col = "steelblue", 
     pch = 20,
     main = "Linear-Log and Cubic Regression Functions")

# add the linear-log regression line
order_id  <- order(CASchools$income)

lines(CASchools$income[order_id],
      fitted(LinearLog_model)[order_id], 
      col = "darkgreen", 
      lwd = 2)

# add the cubic regression line
lines(x = CASchools$income[order_id], 
      y = fitted(cubic_model)[order_id],
      col = "darkred", 
      lwd = 2) 
```
]

---
# 交叉项与交互效应
如果某个独立变量X1对Y的影响取决于另外一个独立变量X2的取值，我们说X1和X2存在交互效应。

之前的例子中，我们可能认为班级规模对学生得分的影响，可能在英语学习者比例高的社区更加显著。这里就需要使用班级规模STR和英语学习者比例english两个变量的交互项来考察它们的交互效应。

交互效应可能有三种形式

1. 两个二元变量交互

2. 一个二元变量和一个连续变量交互

3. 两个连续变量交互

考察如下模型考察大学学历和性别对个人收入的影响：
$$Y_i = \beta_0 + \beta_1 \times D_{1i} + \beta_2 \times D_{2i} + u_i$$
---
# 交互效应实例

假设 Y代表个人收入的对数值，D1表示该人是否具有大学学历，D2表示该人的性别。

加入交叉项考察交互效应
$$Y_i = \beta_0 + \beta_1 \times D_{1i} + \beta_2 \times D_{2i} + \beta_3 \times (D_{1i} \times D_{2i}) + u_i$$
$(D_{1i} \times D_{2i})$ 称为交叉项，$\beta_3$ 衡量的即时交互效应的程度。也就是学历对收入的影响和性别有关。


$$\begin{align*}
  E(Y_i\vert D_{1i}=0, D_{2i} = d_2) =& \, \beta_0 + \beta_1 \times 0 + \beta_2 \times d_2 + \beta_3 \times (0 \times d_2) \\
  =& \, \beta_0 + \beta_2 \times d_2.
\end{align*}$$
$$\begin{align*}
  E(Y_i\vert D_{1i}=1, D_{2i} = d_2) =& \, \beta_0 + \beta_1 \times 1 + \beta_2 \times d_2 + \beta_3 \times (1 \times d_2) \\
  =& \, \beta_0 + \beta_1 + \beta_2 \times d_2 + \beta_3 \times d_2.
\end{align*}$$
$$E(Y_i\vert D_{1i}=1, D_{2i} = d_2) - E(Y_i\vert D_{1i}=0, D_{2i} = d_2) = \beta_1 + \beta_3 \times d_2$$
$\beta_3$ 在此处表示学历对收入的影响的男女差距。

---
# 交互效应实例

创建两个新的二值变量
```{r}
CASchools$HiSTR <- as.numeric(CASchools$size >= 20)
CASchools$HiEL <- as.numeric(CASchools$english >= 10)
```

建立模型
```{r}
bi_model <- lm(score ~ HiSTR * HiEL, data = CASchools)
coeftest(bi_model, vcov. = vcovHC, type = "HC1")
```

---

估计模型为
$$\widehat{TestScore} = \underset{(1.39)}{664.1} - \underset{(1.93)}{1.9} \times HiSTR - \underset{(2.33)}{18.3} \times HiEL - \underset{(3.12)}{3.3} \times (HiSTR \times HiEL)$$
参数解释为：
$$\begin{align*}
\widehat{TestScore} = \hat\beta_0 = 664.1 \quad &\Leftrightarrow \quad HiSTR = 0, \, HIEL = 0\\
\widehat{TestScore} = \hat\beta_0 + \hat\beta_2 = 664.1 - 18.3 = 645.8 \quad &\Leftrightarrow \quad HiSTR = 0, \, HIEL = 1\\
\widehat{TestScore} = \hat\beta_0 + \hat\beta_1 = 664.1 - 1.9 = 662.2 \quad &\Leftrightarrow \quad HiSTR = 1, \, HIEL = 0\\
\widehat{TestScore} = \hat\beta_0 + \hat\beta_1 + \hat\beta_2 + \hat\beta_3  = 664.1 - 1.9 - 18.3 - 3.3 = 640.6 \quad &\Leftrightarrow \quad HiSTR = 1, \, HIEL = 1
\end{align*}$$
验证之：
```{r}
predict(bi_model, newdata = data.frame("HiSTR" = 0, "HiEL" = 0))
predict(bi_model, newdata = data.frame("HiSTR" = 0, "HiEL" = 1))
predict(bi_model, newdata = data.frame("HiSTR" = 1, "HiEL" = 0))
predict(bi_model, newdata = data.frame("HiSTR" = 1, "HiEL" = 1))
```

---
# 连续与二元变量交互
X为某人的工作经历年限，是一个连续变量。

D表示该人是否具有大学学历，是一个二元变量。

可以建立如下三种模型：

1. 同斜率，不同截距
$$Y_i = \beta_0 + \beta_1 X_i + \beta_2 D_i + u_i$$

2. 截距不同，斜率不同
$$Y_i = \beta_0 + \beta_1 X_i + \beta_2 (X_i \times D_i) + u_i.$$

3. 不同斜率，相同截距
$$Y_i = \beta_0 + \beta_1 X_i + \beta_2 D_i + \beta_3 \times (X_i \times D_i) + u_i$$
---
# 三种模型图示
```{r echo=F, fig.align='center', fig.height=7, fig.width=10}
# generate artificial data
set.seed(1)

X <- runif(200,0, 15)
D <- sample(0:1, 200, replace = T)
Y <- 450 +  150 * X + 500 * D + 50 * (X * D) + rnorm(200, sd = 300)
m <- rbind(c(1, 2), c(3, 0))
graphics::layout(m)
plot(X, log(Y),
     pch = 20,
     col = "steelblue",
     main = "Different Intercepts, Same Slope")
mod1_coef <- lm(log(Y) ~ X + D)$coefficients
abline(coef = c(mod1_coef[1], mod1_coef[2]), 
       col = "red",
       lwd = 1.5)
abline(coef = c(mod1_coef[1] + mod1_coef[3], mod1_coef[2]), 
       col = "green",
       lwd = 1.5)
plot(X, log(Y),
     pch = 20,
     col = "steelblue",
     main = "Different Intercepts, Different Slopes")
mod2_coef <- lm(log(Y) ~ X + D + X:D)$coefficients
abline(coef = c(mod2_coef[1], mod2_coef[2]), 
       col = "red",
       lwd = 1.5)
abline(coef = c(mod2_coef[1] + mod2_coef[3], mod2_coef[2] + mod2_coef[4]), 
       col = "green",
       lwd = 1.5)
plot(X, log(Y),
     pch = 20,
     col = "steelblue",
     main = "Same Intercept, Different Slopes")
mod3_coef <- lm(log(Y) ~ X + X:D)$coefficients
abline(coef = c(mod3_coef[1], mod3_coef[2]), 
       col = "red",
       lwd = 1.5)
abline(coef = c(mod3_coef[1], mod3_coef[2] + mod3_coef[3]), 
       col = "green",
       lwd = 1.5)
```

---
# 实例
建立如下模型：
$$\widehat{TestScore_i} = \beta_0 + \beta_1 \times size_i + \beta_2 \times HiEL_i + \beta_2 (size_i \times HiEL_i) + u_i.$$
```{r}
bci_model <- lm(score ~ size + HiEL + size * HiEL, data = CASchools)
coeftest(bci_model, vcov. = vcovHC, type = "HC1")
```
$$\widehat{TestScore} = \underset{(11.87)}{682.2} - \underset{(0.59)}{0.97} \times size + \underset{(19.51)}{5.6} \times HiEL - \underset{(0.97)}{1.28} \times (size \times HiEL).$$
---
# 模型解释
这是一个变截距变斜率模型，对于一个来自于低英语学习比例社区的人 $HiEL_i=0$：
$$\widehat{TestScore} = 682.2 - 0.97\times size_i.$$
对于 $HiEL_i\ne0$：
$$\begin{align*} 
  \widehat{TestScore} =& \, 682.2 + 5.6 - 0.97\times size_i - 1.28 \times size_i \\
   =& \, 687.8 - 2.25 \times size_i.
\end{align*}$$

两类人群与size的线性关系，具有不同的截距和斜率。

---

.pull-left[
```{r plot_inter_slope, fig.show='hide'}
id <- CASchools$english >= 10
plot(CASchools$size[!id], CASchools$score[!id],
     xlim = c(0, 27),
     ylim = c(600, 720),
     pch = 20,
     col = "red",
     main = "",
     xlab = "Class Size",
     ylab = "Test Score")
points(CASchools$size[id], CASchools$score[id],
     pch = 20,
     col = "green")
coefs <- bci_model$coefficients
abline(coef = c(coefs[1], coefs[2]),
       col = "red",
       lwd = 1.5)
abline(coef = c(coefs[1] + coefs[3], coefs[2] + coefs[4]),
       col = "green", 
       lwd = 1.5 )
legend("topright", 
       pch = c(20, 20), 
       col = c("red", "green"), 
       legend = c("HiEL = 0", "HiEL = 1"))    
```
]

.pull-right[
```{r ref.label = 'plot_inter_slope', echo=F, fig.height=7}
```
]
两类人群与size的线性关系，具有不同的截距和斜率。

---
# 连续变量交互
X1是工作年限，X2是受教育年限，二者都是连续变量，建立如下模型：
$$Y_i = \beta_0 + \beta_1 \times X_{1i} + \beta_2 \times X_{2i} + \beta_3 \times (X_{1i} \times X_{2i}) + u_i$$
给定 $X_2$ 的水平, $X_1$ 的变化对 $Y$ 的影响为
$$\frac{\Delta Y}{\Delta X_1} = \beta_1 + \beta_3 X_2.$$

同理:
$$\frac{\Delta Y}{\Delta X_2} = \beta_2 + \beta_3 X_1$$
均体现了二者对Y的交互影响。
$$\begin{align}
\Delta Y_i = (\beta_1 + \beta_3 X_2) \Delta X_1 + (\beta_2 + \beta_3 X_1) \Delta X_2 + \beta_3\Delta X_1 \Delta X_2. \tag{8.2}
\end{align}$$

---
# 数据实例
```{r}
cci_model <- lm(score ~ size + english + english * size, data = CASchools) 
coeftest(cci_model, vcov. = vcovHC, type = "HC1")
```

模型估计为:
$$\widehat{TestScore} = \underset{(11.76)}{686.3} - \underset{(0.59)}{1.12} \times STR - \underset{(0.37)}{0.67} \times PctEL + \underset{(0.02)}{0.0012} \times (STR\times PctEL).$$
**[练习]**尝试解释 $\beta_3$，虽然其估计值不显著。

---
# 实例
```{r}
data("Journals")
Journals$PricePerCitation <- Journals$price/Journals$citations
Journals$Age <- 2000 - Journals$foundingyear
Journals$Characters <- Journals$charpp * Journals$pages/10^6
Journals$Subscriptions <- Journals$subs
```
尝试建立如下四个模型:
$$\begin{align*}
  (I)\quad \ln(Subscriptions_i) =& \, \beta_0 + \beta_1 \ln(PricePerCitation_i) + u_i \\
  \\
  (II)\quad \ln(Subscriptions_i) =& \, \beta_0 + \beta_1 \ln(PricePerCitation_i) + \beta_4 \ln(Age_i) + \beta_6 \ln(Characters_i) + u_i \\
  \\
  (III)\quad \ln(Subscriptions_i) =& \, \beta_0 + \beta_1 \ln(PricePerCitation_i) + \beta_2 \ln(PricePerCitation_i)^2 \\
  +& \, \beta_3 \ln(PricePerCitation_i)^3 + \beta_4 \ln(Age_i) + \beta_5 \left[\ln(Age_i) \times \ln(PricePerCitation_i)\right] \\ +& \, \beta_6 \ln(Characters_i) + u_i \\
  \\
  (IV)\quad \ln(Subscriptions_i) =& \, \beta_0 + \beta_1 \ln(PricePerCitation_i) + \beta_4 \ln(Age_i) + \beta_6 \ln(Characters_i) + u_i
\end{align*}$$

---
```{r}
m1 <- lm(log(Subscriptions) ~ log(PricePerCitation), 
                    data = Journals)
m2 <- lm(log(Subscriptions) ~ log(PricePerCitation) 
                    + log(Age) + log(Characters), 
                    data = Journals)
m3 <- lm(log(Subscriptions) ~ 
                    log(PricePerCitation) + I(log(PricePerCitation)^2) 
                    + I(log(PricePerCitation)^3) + log(Age) 
                    + log(Age):log(PricePerCitation) + log(Characters), 
                    data = Journals)
m4 <- lm(log(Subscriptions) ~ 
                    log(PricePerCitation) + log(Age) 
                    + log(Age):log(PricePerCitation) + 
                    log(Characters), 
                    data = Journals)
```

$$
\begin{align*}
  (I)\quad \widehat{\ln(Subscriptions_i)} =& \, 4.77 - 0.53 \ln(PricePerCitation_i) \\
  (II)\quad \widehat{\ln(Subscriptions_i)} =& \, 3.21 - 0.41 \ln(PricePerCitation_i) + 0.42 \ln(Age_i) + 0.21 \ln(Characters_i) \\
  (III)\quad \widehat{\ln(Subscriptions_i)} =& \, 3.41 - 0.96 \ln(PricePerCitation_i) + 0.02 \ln(PricePerCitation_i)^2 \\
  &+ 0.004 \ln(PricePerCitation_i)^3 + 0.37 \ln(Age_i) \\
  &+ 0.16 \left[\ln(Age_i) \times \ln(PricePerCitation_i)\right] \\ &+ 0.23 \ln(Characters_i) \\
  (IV)\quad \widehat{\ln(Subscriptions_i)} =& \, 3.43 - 0.90 \ln(PricePerCitation_i) + 0.37 \ln(Age_i) \\ 
  &+ 0.14 \left[\ln(Age_i) \times \ln(PricePerCitation_i)\right] + 0.23 \ln(Characters_i)
\end{align*}
$$
---
```{r highlight.output = 10, echo=F}
tab_model(m1, m2, m3, m4, emph.p = T,
          show.fstat = T, title = "Regression Outputs",
          show.ci = F, collapse.se = T, 
          p.style = "a")
```

---
# 图示

.pull-left[

结合回归输出表和右图，我们可以得出什么结论

1. 对于journal的需求，年轻journal的弹性要高于年限长的journal

2. 图b的线性关系是显著的，二次项和三次项回归系数均不显著，因此非线性模型没有必要。

3. 需求弹性与期刊文章的字数多少有关，在price和age不变的条件下，字数越多，需求弹性越大。

总体来说，需求的弹性是很弱的，也就是说，图书馆对于期刊的需求量对于价格是相当不敏感的。

对于age = 5的年轻期刊，需求的价格弹性可以估计为 $-0.899+0.374\times\ln(5)+0.141\times\left[\ln(1)\times\ln(5)\right] \approx -0.3$, 即价格增加1%，需求量只会下降0.3%。

这个结论与实际相符吗？

]

.pull-right[

```{r echo=F, fig.height=7}
m <- rbind(c(1, 2), c(3, 0))
graphics::layout(m)
plot(Journals$PricePerCitation, 
     Journals$Subscriptions, 
     pch = 20, 
     col = "steelblue",
     ylab = "Subscriptions",
     xlab = "ln(Price per ciation)",
     main = "(a)")
plot(log(Journals$PricePerCitation), 
     log(Journals$Subscriptions), 
     pch = 20, 
     col = "steelblue",
     ylab = "ln(Subscriptions)",
     xlab = "ln(Price per ciation)",
     main = "(b)")
abline(m1,
       lwd = 1.5)
plot(log(Journals$PricePerCitation), 
     log(Journals$Subscriptions), 
     pch = 20, 
     col = "steelblue",
     ylab = "ln(Subscriptions)",
     xlab = "ln(Price per ciation)",
     main = "(c)")
JM4C <-m4$coefficients
abline(coef = c(JM4C[1] + JM4C[3] * log(80), 
                JM4C[2] + JM4C[5] * log(80)),
       col = "darkred",
       lwd = 1.5)
abline(coef = c(JM4C[1] + JM4C[3] * log(5), 
                JM4C[2] + JM4C[5] * log(5)),
       col = "darkgreen",
       lwd = 1.5)
```
]

























