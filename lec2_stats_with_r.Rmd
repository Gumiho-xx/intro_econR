---
title: "统计分析基础与R"
subtitle: ""
author: "冯凌秉"
institute: "<span style = 'font-size: 70%;'>
  江西财经大学 <br> 
  产业经济研究院</span>"
date: '2020<br><br>
  `r icon::fa("paper-plane")` <feng.lingbing@jxufe.edu.cn>'
output:
  xaringan::moon_reader:
    css: [default, zh-CN.css]
    lib_dir: libs
    includes:
      after_body: insert-logo.html
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---
```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = ">", fig.retina = 3, warning = FALSE, message = FALSE)
```

# 总体均值的估计

.pull-left[
感兴趣的现象：大学毕业生的收入

变量：大学毕业生工作每小时的收入 $Y$.

数据（样本）: $Y_1, Y_2, \cdots, Y_n$.

感兴趣的总体特征：大学毕业生的平均收入 $\mu_Y$.

我们的问题是：用什么来估计 $\mu_Y$？

根据上节课的内容，你的回答也许是：使用样本均值 $\overline{Y}$

样本均值只是所有对 $\mu_Y$ 进行估计的统计量之一。

有没有其他估计量？他们会不会比 $\mu_Y$更好？

假设 $Y$ 的分布是 $Y \sim \chi_{12}^2$, 取100个随机样本。
]

.pull-right[
```{r fig.height=3}
curve(dchisq(x, df=12), 
      from = 0, 
      to = 40, 
      ylab = "density", 
      xlab = "hourly earnings in Euro")
set.seed(1)
rsamp <- rchisq(n = 100, df = 12)
rsamp[1]
```
]

---
# 总体均值的估计 （2）

假设我们用第一个观测值8.26作为 $\mu_Y$（真实值为12）的估计值。效果好像不算太差。

这里我们对于估计量的好坏已经有了一个潜意识的标准，就是估计值与真实值的差距。这叫做偏差(bias). 这里的偏差值等于  8.26 - 12 = -3.74。

但这里的样本并不是总体，只是所有可能样本中的一个，因此 $Y_1$ 也是个随机变量。如果重新观测一次样本，我们很有可能得到不一样的 $Y_1$.


```{r}
set.seed(2)
rsamp2 <- rchisq(n = 100, df = 12)
rsamp2[1]
```
这一次第一个观测值变成了7.2。偏差变大了。如果重复这样的操作，我们会发现用 $Y_1$ 作为 $\mu_Y$ 的估计，他的偏差时而大时而小，是不稳定的。这样的不稳定性一般用 $Y_1$ 的方差来测度。
$$\text{Var}(Y_1) = \text{Var}(Y) = 2 \cdot 12 = 24$$

---

# 总体均值的估计 （3）

思考一个问题: $Y_1$ 作为一个估计值，它的平均偏差是多少？也就是
$$
E(\hat\mu_{Y_1}) - \mu_Y = ?
$$
可以证明和模拟得到，这个偏差等于0。也就意味着 $Y_1$ 的bias = 0。这样的估计值我们称为 **无偏估计**。

有没有比 $Y_1$ 更好的无偏估计量呢？由大数定律我们知道，样本均值也是一个无偏估计量，而且它的不确定性（方差）为 $\text{Var}(Y)/n$，也就是
$$\text{Var}(\overline{Y}) = \text{Var}(Y)/n = 2 \cdot 12 /n = 24/n$$

同样是无偏估计量，样本均值 $\overline{Y}$ 比 $Y_1$ 具有更小的不确定性 ( $n > 1$ 即可)。这样的性质我们称为有效性 (efficiency)。估计量的方差越小越有效。

因此 $\overline{Y}$ 比 $Y_1$，是一个更加有效的估计量。同样是样本均值，n越大，越有效。

.footnote[[拓展] 估计量三个性质，还有一个叫做一致性，其具体含义参考教材。
]

---
# 无偏性与有效性

.pull-left[
```{r plot_1, fig.show = 'hide'}
pop <- rnorm(10000, 10, 1)
est1 <- replicate(expr = mean(sample(x = pop, size = 5)), n = 25000)
est2 <- replicate(expr = mean(sample(x = pop, size = 25)), n = 25000)
fo <- replicate(expr = sample(x = pop, size = 5)[1], n = 25000)
plot(density(fo), col = 'green', lwd = 2,
      ylim = c(0, 2),xlab = 'estimates',
      main = 'Sampling Distributions of Unbiased Estimators')
lines(density(est1), col = 'steelblue', lwd = 2, bty = 'l')
lines(density(est2), col = 'red2', lwd = 2)
abline(v = 10, lty = 2)
curve(dnorm(x, mean = 10), lwd = 2,lty = 2,add = T)
legend("topleft",legend = c("N(10,1)",expression(Y[1]),
      expression(bar(Y) ~ n == 5), expression(bar(Y) ~ n == 25)), 
      lty = c(2, 1, 1, 1), col = c('black','green', 'steelblue', 'red2'),lwd = 2)
```
]


.pull-right[
```{r ref.label = 'plot_1', echo=F}
```
]



### 三个估计量，孰优孰劣？

.footnote[[练习：]修改以上代码中的n值，观察不同样本量的样本均值的有效性变化。]

---
# 最小二乘估计量

.pull-left[
一个估计量 $m$，我们希望它与 $Y_i$ 的平均距离之和最小，也就是我们希望 $m$ 可以最小化
$$\begin{equation}
  \sum_{i=1}^n (Y_i - m)^2. \tag{3.1}
\end{equation}$$

$Y_i - m$ 可以理解为用 $m$ 估计 $Y_i$ 时犯错误的程度 （离差）。将其平方(squares) 求和是为了避免正的错误与负的错误相抵消。如果 $m$ 可以最小化这个离差平方和，我们称 $m$ 是一个最小二乘估计量。

可以证明 $m = \overline{Y}$ 就是这样的估计量。
]
.pull-right[
```{r fig.height=4.5}
# define the function and vectorize it
sqm <- function(m) {sum((y-m)^2)}
sqm <- Vectorize(sqm)
y <- rnorm(100, 10, 1)
curve(sqm(x), from = -50, to = 70,xlab = "m",ylab = "sqm(m)")
abline(v = mean(y), lty = 2, col = "darkred")
text(x = mean(y), y = 0, labels = paste(round(mean(y), 2)))
```

]

.footnote[[练习：] 理解`Vectorize( )`函数的作用，理解向量化函数和原函数的区别。]

---
# i.i.d 假设与无偏性

.pull-left[
独立同分布假设对于样本均值的无偏性十分重要。

假设我们现在改变抽样策略，不采用随机抽样，而假设最小的25%的数据获得抽样的概率更高。然后计算均值估计量的抽样分布。

这不是一个随机抽样 (randomized sampling)，而是一个有选择偏差 (selection bias) 的抽样 (更倾向于抽到取值较小的样本)

右图可知：选择偏差导致估计量 $\overline{Y}$ 表现出了对 $\mu_Y$ 的系统性低估。
]

.pull-right[
```{r fig.height=4.5}
est3 <-  replicate(n = 25000, expr = mean(sample(x = sort(pop), 
                  size = 10, prob = c(rep(4, 2500), rep(1, 7500)))))

plot(density(est2), col = 'steelblue', lwd = 2,xlim = c(8, 11),
      xlab = 'Estimates', main = 'When the i.i.d. Assumption Fails')

lines(density(est3),col = 'red2',lwd = 2)
legend("topleft",legend = c(expression(bar(Y)[n == 25]~", i.i.d. fails"),
      expression(bar(Y)[n == 25]~", i.i.d. holds")), 
      lty = c(1, 1), col = c('red2', 'steelblue'),lwd = 2)
```
]

.footnote[[练习:] 修改代码，将选择偏差偏误改为高估。]

---
# 总体均值的假设检验

假设检验需要设定原假设和备择假设，然后观察样本的结果是不是足够拒绝原假设。

- 原假设 $H_0: E(Y) = \mu_{Y,0}.$ <=====> 备择假设: $H_1: E(Y) \neq \mu_{Y,0}$

(以上称为双侧检验)

那么所谓p值指的是在原假设为真的情况下，实际观察到的样本均值或者更极端样本均值的可能性。
$$\begin{equation}
p \text{-value} = P_{H_0}\left[ \lvert \overline{Y} - \mu_{Y,0} \rvert > \lvert \overline{Y}^{act} - \mu_{Y,0} \rvert \right] \tag{3.2}
\end{equation}$$

根据中心极限定理，在原假设成立时
$$\overline{Y} \approx \mathcal{N}(\mu_{Y,0}, \, \sigma^2_{\overline{Y}}) \ \ , \ \ \sigma^2_{\overline{Y}} = \frac{\sigma_Y^2}{n}$$
$$
\frac{\overline{Y} - \mu_{Y,0}}{\sigma_Y/\sqrt{n}} \sim \mathcal{N}(0,1).
$$
因此，p值的计算不需要知道 $\overline{Y}$ 真实的抽样分布。

---
# 标准差已知

如果Y的标准差已知，则p值的计算为：

因此，p值就是标准正态分布两侧尾部的面积之和：

.pull-left[
$$
\begin{align}
p \text{-value} =& \, P_{H_0}\left[ \left\lvert \frac{\overline{Y} - \mu_{Y,0}}{\sigma_{\overline{Y}}} \right\rvert > \left\lvert \frac{\overline{Y}^{act} - \mu_{Y,0}}{\sigma_{\overline{Y}}} \right\rvert \right] \\
=& \, 2 \cdot \Phi \left[ - \left\lvert \frac{\overline{Y}^{act} - \mu_{Y,0}}{\sigma_{\overline{Y}}}  \right\rvert\right].  \tag{3.3}
\end{align}
$$

$$
\begin{equation}
\pm \left\lvert \frac{\overline{Y}^{act} - \mu_{Y,0}}{\sigma_{\overline{Y}}} \right\rvert \tag{3.4}
\end{equation}
$$
]

.pull-right[

```{r echo=F, fig.height=7, fig.align='right'}
# plot the standard normal density on the interval [-4,4]
curve(dnorm(x),
      xlim = c(-4, 4),
      main = 'p-Value',
      yaxs = 'i',
      xlab = 'z',
      ylab = '',
      lwd = 2,
      axes = 'F')
axis(1, 
     at = c(-1.5, 0, 1.5), 
     padj = 0.75,
     labels = c(expression(-frac(bar(Y)^"act"~-~bar(mu)[Y,0], sigma[bar(Y)])),
                0,
                expression(frac(bar(Y)^"act"~-~bar(mu)[Y,0], sigma[bar(Y)]))))
polygon(x = c(-6, seq(-6, -1.5, 0.01), -1.5),
        y = c(0, dnorm(seq(-6, -1.5, 0.01)),0), 
        col = 'steelblue')
polygon(x = c(1.5, seq(1.5, 6, 0.01), 6),
        y = c(0, dnorm(seq(1.5, 6, 0.01)), 0), 
        col = 'steelblue')
```

]

---
# Y标准差未知时

如果 $\sigma_Y^2$ 未知，则需要通过样本估计得知。样本标准差 $s_Y$ 是总体标准差  $\sigma_Y$ 的一致估计
$$\begin{equation}
s_Y = \sqrt{\frac{1}{n-1} \sum_{i=1}^n (Y_i - \overline{Y})^2}
\end{equation}, s_Y \overset{p}{\longrightarrow} \sigma_Y.$$

```{r echo=F, fig.height=5, fig.align='center'}
# vector of sample sizes
n <- c(10000, 5000, 2000, 1000, 500)

# sample observations, estimate using 'sd()' and plot the estimated distributions
sq_y <- replicate(n = 10000, expr = sd(rnorm(n[1], 10, 10)))
plot(density(sq_y),
     main = expression('Sampling Distributions of' ~ s[Y]),
     xlab = expression(s[y]),
     lwd = 2)

for (i in 2:length(n)) {
  sq_y <- replicate(n = 10000, expr = sd(rnorm(n[i], 10, 10)))
  lines(density(sq_y), 
        col = i, 
        lwd = 2)
}

# add a legend
legend("topleft",
       legend = c(expression(n == 10000),
                  expression(n == 5000),
                  expression(n == 2000),
                  expression(n == 1000),
                  expression(n == 500)), 
       col = 1:5,
       lwd = 2)
```

随着抽样规模的增加，样本标准差逐渐夹紧总体标准差。

---
# 标准误与p值

标准误：一个估计量的标准差的估计值，叫做这个估计量的标准误 (standard error)。
$$SE(\overline{Y}) = \hat\sigma_{\overline{Y}} = \frac{s_Y}{\sqrt{n}}$$
因此，当 $\sigma_Y$ 未知时，公式（3.4）中的 $\sigma_{\overline{Y}}$ 应该被 
$SE(\overline{Y}) = \hat\sigma_{\overline{Y}}$ 取代，

因此P值计算公式为：
$$
p\text{-value} = 2\cdot\Phi\left(-\left\lvert \frac{\overline{Y}^{act}-\mu_{Y,0}}{SE(\overline{Y})} \right\rvert \right).
$$

这里我们依然认为以下统计量服从正态分布
$$
\begin{equation}
Z = \frac{\overline{Y} - \mu_{Y,0}}{SE(\overline{Y})} \tag{3.5}
\end{equation}
$$

---
# t分布的正态近似

但其实上一页的统计量 （公式 3.5）就是著名的 $t$ 统计量，严格来说，它服从学生 $t$ 分布。

如果样本量足够大，在计算p值时使用正态分布并没有多大问题，正态分布可以很好的近似t分布。
```{r echo=F, fig.align='center', fig.height=5}
# prepare empty vector for t-statistics
tstatistics <- numeric(10000)

# set sample size
n <- 300

# simulate 10000 t-statistics
for (i in 1:10000) {
  
  s <- sample(0:1, 
              size = n,  
              prob = c(0.9, 0.1),
              replace = T)
  
  tstatistics[i] <- (mean(s)-0.1)/sqrt(var(s)/n)
  
}
# plot density and compare to N(0,1) density
plot(density(tstatistics),
     xlab = 't-statistic',
     main = 'Estimated Distribution of the t-statistic when n=300',
     lwd = 2,
     xlim = c(-4, 4),
     col = 'steelblue')

# N(0,1) density (dashed)
curve(dnorm(x), 
      add = T, 
      lty = 2, 
      lwd = 2)
```

---
# 两类错误与显著性水平

在假设检验中，我们可能会犯两类错误：
1. 原假设为真，但被我们拒绝了，这被称为I-类错误
2. 原假设为假，但我们没有拒绝，这被称为II-类错误。

所谓显著性水平指的是我们能够结构的犯I-类错误的最大程度，一般设定为5%。如果设定为10% 表示我们更加宽容，设定为1%表示我们更加严格。

在假设检验之前，显著性水平是事先设定的。如果计算的p值小于显著性水平，则表示我们有足够的证据支持拒绝原假设的决定。

除了用p值做决定，我们可以使用拒绝域。拒绝域是检验统计量分布尾部大于某个临界值的区域，如果检验统计量值落在该区域，则拒绝原假设。

临界值的计算取决于检验统计的分布和显著性水平的设定。对于均值假设检验，我们一般使用1.96。
```{r}
qnorm(p = 0.975)
```

---
# 单侧假设检验

如果我们感兴趣的是检验均值是否大于或者小于某个值，则备择假设将做相应修订

$$H_0: \mu_Y = \mu_{Y,0} \ \ \text{vs} \ \ H_1: \mu_Y > \mu_{Y,0}$$
此时我们的临界值为t > 1.64，相应的拒绝域为单侧 (右侧)拒绝域

```{r}
qnorm(0.95)
```


```{r echo=F, fig.align='center', fig.height=4}
# plot the standard normal density on the domain [-4,4]
curve(dnorm(x),
      xlim = c(-4, 4),
      main = 'Rejection Region of a Right-Sided Test',
      yaxs = 'i',
      xlab = 't-statistic',
      ylab = '',
      lwd = 2,
      axes = 'F')

# add the x-axis
axis(1, 
     at = c(-4, 0, 1.64, 4), 
     padj = 0.5,
     labels = c('', 0, expression(Phi^-1~(.95)==1.64), ''))

# shade the rejection region in the left tail
polygon(x = c(1.64, seq(1.64, 4, 0.01), 4),
        y = c(0, dnorm(seq(1.64, 4, 0.01)), 0), 
        col = 'darkred')
```

---
# 置信水平与置信区间

所谓置信区间 (Confidence Interval, CI)，是指在一定的置信水平 (比如95%)下，重复抽样获得的很多个这样的置信区间能够覆盖真值的区间比例等于置信水平。<sup>*</sup>

一般来说，置信水平 = 1 - 显著性水平。

$$
\begin{align}
&99\%\text{ CI for } \mu_Y = \left[ \overline{Y} \pm 2.58 \times SE(\overline{Y}) \right], \\
&95\%\text{ CI for } \mu_Y = \left[\overline{Y} \pm 1.96 \times SE(\overline{Y}) \right], \\
&90\%\text{ CI for } \mu_Y = \left[ \overline{Y} \pm 1.64 \times SE(\overline{Y}) \right].
\end{align}
$$

不信？可以[看看这个动画](https://rpsychologist.com/d3/CI/)

置信区间本身也是个随机变量，因此在频率学派看来，不能说置信区间有多大的概率包含真值。

当一个置信区间计算出来之后，它要么包含真值，要么不包含。

只有在重复抽样获得多个置信区间后，才能计算概率。




---
# t检验

.pull-left[
两种安眠药效果的均值比较。

```{r}
plot(extra ~ group, data = sleep)
```
]
.pull-right[
extra表示服用某组（一共两组）药物后增加的睡眠时间。

从左图来看，第二部药物提高的睡眠时间要比第一组更多。

但是这个差距是否是统计意义上显著的“？可以用t检验。
```{r}
with(sleep, t.test(extra[group == 1], extra[group == 2]))
```
]


---

# 应用: Table 3.1
```{r eval=F}
library(readxl)
cps <- read_excel(path = 'cps_ch3.xlsx')
library(dplyr)
head(cps)
avgs <- cps %>% 
        group_by(a_sex, year) %>% 
        summarise(mean(ahe08), 
                  sd(ahe08), 
                  n())

male <- avgs %>% filter(a_sex == 1) 
female <- avgs %>% filter(a_sex == 2)
colnames(male)   <- c("Sex", "Year", "Y_bar_m", "s_m", "n_m")
colnames(female) <- c("Sex", "Year", "Y_bar_f", "s_f", "n_f")
# estimate gender gaps, compute standard errors and confidence intervals for all dates
gap <- male$Y_bar_m - female$Y_bar_f
gap_se <- sqrt(male$s_m^2 / male$n_m + female$s_f^2 / female$n_f)
gap_ci_l <- gap - 1.96 * gap_se
gap_ci_u <- gap + 1.96 * gap_se
result <- cbind(male[,-1], female[,-(1:2)], gap, gap_se, gap_ci_l, gap_ci_u)
print(result, digits = 3)
```

---
# 散点图：连续型变量的相关关系
```{r fig.height=5}
X <- runif(n = 100, min = 18, max = 70); Y <- X + rnorm(n=100, 50, 15)
plot(X, Y, type = "p",main = "A Scatterplot of X and Y",xlab = "Age",
     ylab = "Earnings",col = "steelblue",pch = 19)
```


---
# 协方差与相关系数

给定样本，可以计算两个变量的样本协方差
$$s_{XY} = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y})$$

和样本相关系数 $$r_{XY} = \frac{s_{XY}}{s_Xs_Y}$$

```{r}
cov(X, Y)
cor(X, Y)
cov(X, Y) / (sd(X) * sd(Y))
```

还有两个常见的相关系数测度，分别是Spearman 秩相关系数和Kendall's $\tau$.

[查找资料，掌握三种相关系数测度的使用场景]
---
# Pearson 相关系数的局限性
```{r echo=F ,fig.align='center', fig.height=6}
library(MASS)

# set random seed
set.seed(1)

# positive correlation (0.81)
example1 <- mvrnorm(100,
                    mu = c(0, 0), 
                    Sigma = matrix(c(2, 2, 2, 3), ncol = 2),
                    empirical = TRUE)

# negative correlation (-0.81)
example2 <- mvrnorm(100,
                    mu = c(0, 0), 
                    Sigma = matrix(c(2, -2, -2, 3), ncol = 2),
                    empirical = TRUE)

# no correlation 
example3 <- mvrnorm(100,
                    mu = c(0, 0), 
                    Sigma = matrix(c(1, 0, 0, 1), ncol = 2),
                    empirical = TRUE)

# no correlation (quadratic relationship)
X <- seq(-3, 3, 0.01)
Y <- - X^2 + rnorm(length(X))

example4 <- cbind(X, Y)

# divide plot area as 2-by-2 array
par(mfrow = c(2, 2))

# plot datasets
plot(example1, col = 'steelblue', pch = 20, xlab = 'X', ylab = 'Y', 
     main = "Correlation = 0.81")

plot(example2, col = 'steelblue', pch = 20, xlab = 'X', ylab = 'Y', 
     main = "Correlation = -0.81")

plot(example3, col = 'steelblue', pch = 20, xlab = 'X', ylab = 'Y', 
     main = "Correlation = 0")

plot(example4, col = 'steelblue', pch = 20, xlab = 'X', ylab = 'Y', 
     main = "Correlation = 0")
```

---
# 相关系数矩阵
在变量个数小于30个时，相关系数矩阵可视化是总览变量线性相关关系的[好工具](http://www.sthda.com/english/wiki/visualize-correlation-matrix-using-correlogram)
.pull-left[
```{r eval=F}
library(corrplot)
M<-cor(mtcars)
source("cor_mtest.R")
# matrix of the p-value of the correlation
p.mat <- cor.mtest(mtcars)
library(RColorBrewer)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```

]

.pull-right[
```{r echo=F, fig.height=6}
library(corrplot)
M<-cor(mtcars)
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(mtcars)
library(RColorBrewer)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```
]






















